Oct. 4. 2010
- grad(pressure) on a sheet of particles: nonzero on boundary, zero in interior (makes sense). 

TODO: understand better boundary properties. 
----------------------------------------------------------------------
If timestep is too large, code crashes after some time. 
Otherwise (smaller time step), no crash, even if particles crunch together. 

How to prevent over-crunching?
----------------------------------------------------------------------
Could gain speed on non-Fermi with textures (probably factor 2)
(see Krog thesis)
----------------------------------------------------------------------
Oct. 10, 2010
Compute dt (limit due to acoustics) (gas constant) and velocity
dt1 = 0.5*max(dx/(|vmax|+c) 
p = K (rho-rho0)
c^2 = dp/drho = K
dt1 = 0.5*max(dx(|vmax|+c)
----------------------------------------------------------------------
Making progress: something wrong in 4th component of the force. 

//----------------------------------------------------------------------
Oct. 11, 2010
With scale_to_simulation: Must check values in Fluid v.2 (on Ubuntu, put 
print statements). What is particle spacing and grid size and simulation_scale?
My code does not match up, and I make the sim_scale .005 instead of .05, which 
is most likely wrong. Check creation of grid itself.

Problem is spacing between particles. 
----------------------------------------------------------------------
Oct. 17, 2010
----- GE_SPHParams ----
grid_min: -256.000000, 0.000000, 0.000000, 1.000000
grid_max: 256.000000, 256.000000, 1276.000000, 1.000000
grid_min_padding= 0.000000
grid_max_padding= 0.000000
mass= 0.006400
rest_distance= 0.016153
rest_density= 1000.000000
smoothing_distance= 0.032305
particle_radius= 16.152729
simulation_scale= 0.001000
boundary_stiffness= 10000.000000
boundary_dampening= 256.000000
boundary_distance= 0.008076
EPSILON= 0.000010
PI= 3.141593
K= 20.000000
dt= 0.001500

----- GE_SPHSettings ----
rest_density: 1000.000000
simulation_scale: 0.001000
particle_mass: 0.000205
smoothing_distance: 0.036915
particle_radius: 0.003660
boundary_distance: 0.003660
particle_spacing: 0.016153
grid_cell_size: 0.000000

Beautiful with xsph (fact=0.005) and K=20

Higher K, smaller time step, more incompressible. 
----------------------------------------------------------------------
BUG? 8k particles, dt=0.0005, particles exit on top boundary and code crashes. 
dt=0.0001, particles exit on left boundary (they are moving slowly, yet
seem to exit the boundary. Must be boundary instability. Or error in the code. 

Rotating the domain, I find that particles are moving among the positive
y axis (near max y) more rapidly than those for min y. WHY?

The asymmetry goes away when I use vel instead veleval in the evaluation of viscosity, pressure and xsph. I have no idea why. 
----------------------------------------------------------------------
Oct. 18, 2010
- Problem: sset does not work. Set the value of a constant. 
----------------------------------------------------------------------
Oct. 18, 2010
- nb grid cells is not increasing with number of points.
- too few neighbors (< 8) many times 1
TODO: (debugging)
8k particles, dt=0.0003
Run cases with 
        position[num-i-1] = float4(x,y,z,1.0f);
        //position[i] = float4(x,y,z,1.0f);
They give different results. 
PRINT out sorted positions and indices for both cases. Store in two output files.  Compare the output files.  Something must be different between the two cases. 
INVESTIGATE why there are so few particles in a sphere. 

- Hashes are always in order (regardless of position[] order)
- I must check the order of position array. In sorted form, they should 
be identical. So why is there divergence eventually? 

Hypothesis: search for neighbors is incorrect. WHY ARE THERE SO FEW? 
Smoothing distance = 2*rest_distance. So there are very few particles per
sphere. I should probably make smoothing distance SLIGHTLY larger than 
twice rest_distance. 
----------------------------------------------------------------------

Get sset() to work, which will speed up hashing. 
----------------------------------------------------------------------
Two cases: positions fwd to back, and back to fwd ordering.
Single iteration. 
Sorted hashes/indices are identical at iteration 1. 
Particles in cell 1 are identical, but in different order. 
Densities of corresponding particles are identical. 
Velocities of corresponding particles are not identical!!!!

HURRAY! There is a bug, but now must be found. 
----------------------------------------------------------------------
Problem may be in cell_indexes_start
----------------------------------------------------------------------
sorted veleval list in the two runs are in opposite orders. SHOULD NOT HAPPEN!
----------------------------------------------------------------------
Oct. 20, 2010
- there was a bug in the sorting macros in cl_macros.h . Fixed. 
Speed on Fermi is only 8x the speed on the mac. WHY? There must be inefficiencies somewhere!! This difference is true for leapfrog, pressure, density. 
10 subiterations between renders. Render all particles as 10x10 spheres. 

MacOSX: Nvidia 330
16k particles, render every 10 iterations. 
hash: tot (ms): 149.745, avg: 0.379101, (count=395)
build: tot (ms): 175.34, avg: 0.443899, (count=395)
density: tot (ms): 2230.02, avg: 5.64562, (count=395)
pressure: tot (ms): 3752.95, avg: 9.50113, (count=395)
leapfrog: tot (ms): 287.238, avg: 0.727185, (count=395)
update: tot (ms): 7765.37, avg: 221.868, (count=35)
collision wall: tot (ms): 272.901, avg: 0.690889, (count=395)
bitonic sort: tot (ms): 1320.89, avg: 3.34403, (count=395)
(rtps) system update: tot (ms): 7537.41, avg: 215.355, (count=35)
(rtps) render update: tot (ms): 3191.89, avg: 93.8791, (count=34)

Fermi on Laforge
hash: tot (ms): 34.121, avg: 0.0863822, (count=395)
build: tot (ms): 37.183, avg: 0.0941342, (count=395)
density: tot (ms): 343.58, avg: 0.869823, (count=395)
pressure: tot (ms): 492.615, avg: 1.24713, (count=395)
leapfrog: tot (ms): 42.738, avg: 0.108198, (count=395)
update: tot (ms): 1311.84, avg: 37.4811, (count=35)
collision wall: tot (ms): 42.977, avg: 0.108803, (count=395)
bitonic sort: tot (ms): 192.224, avg: 0.486643, (count=395)
(rtps) system update: tot (ms): 1271.95, avg: 36.3414, (count=35)
(rtps) render update: tot (ms): 5040.11, avg: 148.238, (count=34)

----------------------------------------------------------------------
Oct. 21, 2010
z-indexing done. Given (i,j,k on a grid of 1024 x 1024), and return 
the z index. Based on index tables. Done on the CPU. 
Sort particle indices: 

int* zindex;
int* pindex;
for (int i=0; i < nb_el; i++) {
	float4 pos = positions[i]
	int4 cell = calcGrid(pos);
	int z_hash = zhash(cell);
	pindex[i] = i;
	hindex[i] = z_hash;
}
// sort particles with bitonic sort
// computing start and end locations

For each hash, compute start and end locations. 
If I do this on a 1024^1024 grid, I won't have enough memory to store
start and end indices. For now, do the zindexing on a grid of 128^128^128. 
For this, simply make domain go from 0 to 128 in all directions (change grid_res appropriately, and change domain_max in particles/Uniform.cpp.  Still wasteful of memory, but first concentrate on speed. 

So now, I have start/end or start/nb_part for each block, with particles sorted in z-index fashion. 

Next, sort (vel, pos, veleval) (particle attributes). 

Now, how to use shared memory and blocks efficiently. Threads should NOT be 
allocated on a per particle basis. 
----------------------------------------------------------------------
Oct. 22, 2010
- need triplets (start, end, (i,j,k,w=cell), 
which determine the particles that lie in a single block (cell=(i,j,k)). 
I could use the hash, but then I need to extract (i,j,k) from the has, which 
is not that simple, especially with z-indexing. 
Assume 10 particles per block + 27 surrounding blocks (1 particle each). How much shared memory do I require?  Assume 10 variables (floats) per particle. 
Shared: = (32+26)*10*4 = 580*4 = 2320 bytes. The mac has 16k shared memory 
which allows for 6 blocks. Assume each block has 64 threads. That amounts 
to 640 total threads (on the mac).  If each block has 32 threads, then 320 
threads. 

Build this idea into our current code without z-indexing at first. 
Once this is done, consider z-indexing. Pre-compute an array of int4 that 
stores (i,j,k,w) indices for each hash. 
----------------------------------------------------------------------
Create new routines. 
Create constant structure of int4 offsets to quickly scan 27 neighbors. 
----------------------------------------------------------------------
Oct. 23, 2010
- Consider making constant structures and arrays READ ONLY.
----------------------------------------------------------------------
Oct. 24, 2010
- got rid of all uint. 
 casting a uint to a float gives incorrect results. 
----------------------------------------------------------------------
Nov. 7, 2010
- one warp per block: works
- two warps per block: works. Remember that offsets into loc memory
are in float4 units, not bytes. 
- Time decreases by 10% for 2 or 4 warps per block. Very little improvement. 
- What if one warp treats two blocks? 
----------------------------------------------------------------------
Nov. 17, 2010
- perhaps have grid resolution = power of 2? 
- extend grid to make sure there is power of two, without changing boundaries. 
----------------------------------------------------------------------
Nov. 19, 2010
nn_elem= 262144 (grid size)
Compactification of array of integers
330M: 5.2 ms + 9.4 ms = 13.6 ms (too much!!)
  (4 warps per block)
Potentially, I can decrease first stage down to 1.5 ms (better computation of offsets)
Potentially, I can decrease first stage down to 0.8 (cost of compactSIMD)
Both costs above are due to computation done with single thread single warp. Very very 
inefficient, since there are 4 warps and 32 threads per warp! (potential cost: factor
of 128)

Cost should independent of the distribution of invalid elements since all elements 
must be checked. 
----------------------------------------------------------------------
Works! blocks of size 128
Nb cells: 262,000, on the MacOSX, 330M graphics card. 
compactify_sub1: tot (ms): 9.925, avg: 1.985, (count=5)
compactify_sub2: tot (ms): 5.424, avg: 1.0848, (count=5)
compactify_sub2sum: tot (ms): 6.17, avg: 1.234, (count=5)
compactify_sub3: tot (ms): 2.186, avg: 0.4372, (count=5)
compactify_sub4: tot (ms): 48.814, avg: 9.7628, (count=5) <<<< EXPENSIV
(rtps) system update: tot (ms): 0, avg: -0, (count=-4)

----------------------------------------------------------------------
